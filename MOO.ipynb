{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bbc5e6f-315e-4a8e-9635-4e26a5d6c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "dataset_path = './dataset/'\n",
    "dataset_files = ['TcData.csv' ,'BsData.csv']\n",
    "\n",
    "tkwargs = {\n",
    "    \"dtype\": torch.double,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "}\n",
    "\n",
    "dfs = dict([])\n",
    "for file in dataset_files:\n",
    "    df = pd.read_csv(os.path.join(dataset_path,file), na_values=0)\n",
    "    df = df.rename(columns={'Composition': 'formula'})\n",
    "    df.name = file[:2]\n",
    "    dfs[df.name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88581e59-9d8c-4764-a283-716e86b03b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import add_feature\n",
    "\n",
    "load_df = True\n",
    "for df_name, df in dfs.items():\n",
    "    if load_df:\n",
    "        dfs[df_name] = pd.read_pickle(os.path.join(dataset_path, f\"./df_data_{df.name}.pkl\"))\n",
    "    else:    \n",
    "        name = df.name\n",
    "        df = add_feature.add_composition(df)\n",
    "        df = add_feature.add_element_fraction(df)\n",
    "        df.name = name\n",
    "        dfs[df_name] = df \n",
    "        df.to_pickle(os.path.join(dataset_path, f\"./df_data_{df.name}.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d27590-f027-41a1-8dff-f559d85bcd0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.surrogate import surrogate_model\n",
    "\n",
    "Tc_surrogate = surrogate_model(name='Tc', df=dfs['Tc'])\n",
    "Bs_surrogate = surrogate_model(name='Bs', df=dfs['Bs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f87d0c60-d192-42af-9e4c-015e9e34a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tc_surrogate.cleanup_df(drop_NaN = False, drop_col_with_NaN = True)\n",
    "Bs_surrogate.cleanup_df(drop_NaN = False, drop_col_with_NaN = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d1ed59b-35c4-4591-b22b-f770fd029c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([220, 104])\n",
      "-------------------\n",
      "Training Tc\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "Epoch 100/600 - Loss: 1.407 noise: 1.259\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "Epoch 200/600 - Loss: 1.225 noise: 0.547\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "Epoch 300/600 - Loss: 0.730 noise: 0.104\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "Epoch 400/600 - Loss: 0.681 noise: 0.090\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "Epoch 500/600 - Loss: 0.678 noise: 0.089\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "torch.Size([220, 104])\n",
      "Epoch 600/600 - Loss: 0.676 noise: 0.088\n",
      "-------------------\n",
      "torch.Size([294, 104])\n",
      "-------------------\n",
      "Training Bs\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "Epoch 100/600 - Loss: 1.338 noise: 1.144\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "Epoch 200/600 - Loss: 1.179 noise: 0.504\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "Epoch 300/600 - Loss: 1.042 noise: 0.349\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "Epoch 400/600 - Loss: 0.856 noise: 0.185\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "Epoch 500/600 - Loss: 0.827 noise: 0.166\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "torch.Size([294, 104])\n",
      "Epoch 600/600 - Loss: 0.825 noise: 0.165\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "#from botorch.fit import fit_gpytorch_mll\n",
    "from torch.optim import SGD, Adam\n",
    "from botorch.models.transforms.input import ChainedInputTransform\n",
    "from utils.model import trainGP, NormalizeElementFractions, NormalizeFeatures\n",
    "from utils.model import test_features_normalized\n",
    "\n",
    "for surrogate_model in [Tc_surrogate, Bs_surrogate]:\n",
    "    surrogate_model.model = None\n",
    "    outcome_transform = Standardize(m=1)\n",
    "    normalize_other = NormalizeFeatures(indices=surrogate_model.to_scale_col)\n",
    "    normalize_EF = NormalizeElementFractions(indices=surrogate_model.EF_col)\n",
    "    input_transform = ChainedInputTransform(\n",
    "        tf1=normalize_other, \n",
    "        tf2=normalize_EF,\n",
    "    )\n",
    "    \n",
    "    surrogate_model.model = SingleTaskGP(\n",
    "        torch.tensor(surrogate_model.X), \n",
    "        torch.tensor(surrogate_model.y).unsqueeze(dim=1),\n",
    "        input_transform=input_transform,\n",
    "        outcome_transform=outcome_transform,\n",
    "        covar_module=ScaleKernel(RBFKernel()),\n",
    "    )\n",
    "    \n",
    "    print(\"-------------------\")\n",
    "\n",
    "    surrogate_model.model.train()\n",
    "    #optimizer_kwargs = {'lr': 1e-2, 'weight_decay': 1e-3}\n",
    "    optimizer_kwargs = {'lr': 5e-2, 'weight_decay': 1e-4}\n",
    "    print(f\"Training {surrogate_model.name}\")\n",
    "    #surrogate_model.model.train()\n",
    "    trainGP(surrogate_model.model,\n",
    "            mll = ExactMarginalLogLikelihood(surrogate_model.model.likelihood, surrogate_model.model), \n",
    "            optimizer = SGD([{'params': surrogate_model.model.parameters()}], **optimizer_kwargs),\n",
    "            num_epochs=600,\n",
    "            print_interval = 100 \n",
    "           )\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dce0cdd8-15ad-46ef-99f3-5a4d5708eb27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "#from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models.transforms.input import ChainedInputTransform\n",
    "from utils.model import trainGP, NormalizeElementFractions, NormalizeFeatures\n",
    "from utils.model import test_features_normalized\n",
    "\n",
    "def initialize_model(train_x, train_obj):\n",
    "    \n",
    "    models = []\n",
    "    #first index goes over obj_idx\n",
    "    for i in range(train_obj.shape[-1]):\n",
    "        y = train_obj[..., i]\n",
    "        X = train_x\n",
    "        \n",
    "        outcome_transform = Standardize(m=1)\n",
    "        normalize_other = NormalizeFeatures(indices=surrogates[i].to_scale_col)\n",
    "        normalize_EF = NormalizeElementFractions(indices=surrogates[i].EF_col)\n",
    "        input_transform = ChainedInputTransform(\n",
    "            tf1=normalize_other, \n",
    "            tf2=normalize_EF,\n",
    "        )\n",
    "        \n",
    "        model = SingleTaskGP(\n",
    "            X,\n",
    "            y, #.unsqueeze(dim=1), \n",
    "            input_transform=input_transform,\n",
    "            outcome_transform=outcome_transform,\n",
    "            covar_module=ScaleKernel(RBFKernel()),\n",
    "        )\n",
    "        models.append(model)\n",
    "    \n",
    "    model = ModelListGP(*models)\n",
    "    mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
    "    return mll, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa5a17d8-b880-4b52-890e-49eeb5bd6cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from utils.model import trainGPList\n",
    "from torch.optim import Adam, SGD\n",
    "def train_model(modelList: ModelListGP, mllList: SumMarginalLogLikelihood):\n",
    "    modelList.train()\n",
    "    #optimizer_kwargs = {'lr': 1e-2, 'weight_decay': 1e-3}\n",
    "    optimizer_kwargs = {'lr': 3e-2, 'weight_decay': 1e-3}\n",
    "    print(\"-------------------\")\n",
    "    for model, mll in zip(modelList.models, mllList.mlls):\n",
    "    #print(f\"Training {model_name}\")\n",
    "    #surrogate_model.model.train()\n",
    "        trainGP(model,\n",
    "                mll = mll, \n",
    "                optimizer = Adam([{'params': model.parameters()}], **optimizer_kwargs),\n",
    "                num_epochs=50,\n",
    "                print_interval = 100 \n",
    "               )\n",
    "        print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "601e69cd-6840-4519-a108-50cdb707065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOKE_TEST=True\n",
    "surrogates = [Tc_surrogate, Bs_surrogate]\n",
    "ref_point = torch.tensor([np.average(surrogate.y) for surrogate in surrogates],**tkwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70b8e310-5549-41e5-a055-6ad6c37efdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_data(surrogates):\n",
    "    for surrogate in surrogates:\n",
    "        try:\n",
    "            surrogate.df = surrogate.df.drop(['formula', 'composition', surrogate.label],axis=1)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "\n",
    "    total_df = pd.concat([surrogate.df for surrogate in surrogates])\n",
    "    empty_col = total_df.columns[[not total_df[col].any() for col in total_df.columns]]\n",
    "    total_df = total_df.drop(empty_col,axis=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    from utils.model import evaluateGP\n",
    "    X = np.concatenate([surrogate.X for surrogate in surrogates],axis=0)\n",
    "    y = [evaluateGP(surrogate.model, X) for surrogate in surrogates][0]\n",
    "    X = torch.tensor(X, **tkwargs)\n",
    "    y = [torch.tensor(array, **tkwargs) for array in y]\n",
    "    #X = torch.stack((X, X),dim=-1)\n",
    "    y = torch.stack(y,dim=-1).unsqueeze(dim=1)\n",
    "    \n",
    "    return X, y, total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc12dc-7c92-430d-982b-3fb3f81df9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30052cb1-edf2-4414-9cf9-e0e8535617d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.optim.optimize import optimize_acqf, optimize_acqf_list\n",
    "from botorch.acquisition.objective import GenericMCObjective\n",
    "from botorch.utils.multi_objective.scalarization import get_chebyshev_scalarization\n",
    "from botorch.utils.multi_objective.box_decompositions.non_dominated import (\n",
    "    FastNondominatedPartitioning,\n",
    ")\n",
    "from botorch.acquisition.multi_objective.monte_carlo import (\n",
    "    qExpectedHypervolumeImprovement,\n",
    "    qNoisyExpectedHypervolumeImprovement,\n",
    ")\n",
    "from botorch.acquisition.multi_objective.logei import qLogExpectedHypervolumeImprovement\n",
    "from botorch.utils.sampling import sample_simplex\n",
    "from botorch.utils.transforms import unnormalize, normalize\n",
    "\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "NUM_RESTARTS = 10 if not SMOKE_TEST else 2\n",
    "RAW_SAMPLES = 512 if not SMOKE_TEST else 4\n",
    "\n",
    "standard_bounds = torch.zeros(2, 2, **tkwargs)\n",
    "standard_bounds[1] = 1\n",
    "bounds = torch.zeros(2, 104, **tkwargs)\n",
    "bounds[1,:] = 1\n",
    "\n",
    "\n",
    "\n",
    "def optimize_qehvi_and_get_observation(model, train_x, train_obj, sampler):\n",
    "    \"\"\"Optimizes the qEHVI acquisition function, and returns a new candidate and observation.\"\"\"\n",
    "    # partition non-dominated space into disjoint rectangles\n",
    "    with torch.no_grad():\n",
    "        pred = model.posterior(normalize(train_x, bounds)).mean\n",
    "        #pred = torch.concatenate([model.posterior(train_x[:,:,i]).mean for i, model in enumerate(model_qparego.models)],dim=-1)\n",
    "    partitioning = FastNondominatedPartitioning(\n",
    "        ref_point=ref_point,\n",
    "        Y=pred,\n",
    "    )\n",
    "    acq_func = qExpectedHypervolumeImprovement(\n",
    "        model=model,\n",
    "        ref_point=ref_point,\n",
    "        partitioning=partitioning,\n",
    "        sampler=sampler,\n",
    "    )\n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=bounds,\n",
    "        q=BATCH_SIZE,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "        sequential=False,\n",
    "        return_best_only=False,\n",
    "    )\n",
    "    # observe new values\n",
    "    new_x = unnormalize(candidates.detach(), bounds=bounds)\n",
    "    print(new_x.shape)\n",
    "    new_obj_true = torch.stack([model.models[0](new_x).mean, model.models[1](new_x).mean], dim=-1).unsqueeze(1)\n",
    "    #new_obj = new_obj_true + torch.randn_like(new_obj_true) * NOISE_SE\n",
    "    return new_x, new_obj_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c24f726-7f97-4548-91de-54fad1991071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_qnehvi_and_get_observation(model, train_x, train_obj, sampler):\n",
    "    \"\"\"Optimizes the qEHVI acquisition function, and returns a new candidate and observation.\"\"\"\n",
    "    # partition non-dominated space into disjoint rectangles\n",
    "    acq_func = qNoisyExpectedHypervolumeImprovement(\n",
    "        model=model,\n",
    "        ref_point=ref_point.tolist(),  # use known reference point\n",
    "        X_baseline=normalize(train_x, bounds),\n",
    "        prune_baseline=True,  # prune baseline points that have estimated zero probability of being Pareto optimal\n",
    "        sampler=sampler,\n",
    "    )\n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf(\n",
    "        acq_function=acq_func,\n",
    "        bounds=standard_bounds,\n",
    "        q=BATCH_SIZE,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 10, \"maxiter\": 200},\n",
    "        sequential=True,\n",
    "    )\n",
    "    # observe new values\n",
    "    new_x = unnormalize(candidates.detach(), bounds=bounds)\n",
    "    print(new_x.shape)\n",
    "    new_obj_true = torch.stack([model.models[0](train_x).mean, model.models[1](train_x).mean], dim=-1).unsqueeze(1)\n",
    "    #new_obj = new_obj_true + torch.randn_like(new_obj_true) * NOISE_SE\n",
    "    return new_x, new_obj_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4aa6d97-56e9-4399-886d-98f2909490b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition.monte_carlo import qNoisyExpectedImprovement\n",
    "\n",
    "\n",
    "def optimize_qnparego_and_get_observation(model, train_x, train_obj, sampler):\n",
    "    \"\"\"Samples a set of random weights for each candidate in the batch, performs sequential greedy optimization\n",
    "    of the qNParEGO acquisition function, and returns a new candidate and observation.\"\"\"\n",
    "    train_x = normalize(train_x, bounds)\n",
    "    with torch.no_grad():\n",
    "        pred = model.posterior(train_x).mean\n",
    "        #pred = torch.concatenate([model.posterior(train_x[:,:,i]).mean for i, model in enumerate(model_qparego.models)],dim=-1)\n",
    "    acq_func_list = []\n",
    "    for _ in range(BATCH_SIZE):\n",
    "        weights = sample_simplex(2, **tkwargs).squeeze()\n",
    "        objective = GenericMCObjective(\n",
    "            get_chebyshev_scalarization(weights=weights, Y=pred)\n",
    "        )\n",
    "        acq_func = qNoisyExpectedImprovement(  # pyre-ignore: [28]\n",
    "            model=model,\n",
    "            objective=objective,\n",
    "            X_baseline=train_x.clone(),\n",
    "            sampler=sampler,\n",
    "            prune_baseline=False,\n",
    "        )\n",
    "        acq_func_list.append(acq_func)\n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf_list(\n",
    "        acq_function_list=acq_func_list,\n",
    "        bounds=bounds,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "    )\n",
    "    # observe new values\n",
    "    new_x = unnormalize(candidates.detach(), bounds=bounds)\n",
    "    new_obj_true = model(new_x)\n",
    "    #new_obj = new_obj_true + torch.randn_like(new_obj_true) * NOISE_SE\n",
    "    return new_x, new_obj_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "918211a1-7aa1-4966-a5c8-e3ddc98c305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "-------------------\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "-------------------\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "-------------------\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n",
      "torch.Size([514, 104])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingsk/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/botorch/acquisition/multi_objective/monte_carlo.py:203: NumericsWarning: qExpectedHypervolumeImprovement has known numerical issues that lead to suboptimal optimization performance. It is strongly recommended to simply replace\n",
      "\n",
      "\t qExpectedHypervolumeImprovement \t --> \t qLogExpectedHypervolumeImprovement \n",
      "\n",
      "instead, which fixes the issues and has the same API. See https://arxiv.org/abs/2310.20708 for details.\n",
      "  legacy_ei_numerics_warning(legacy_name=type(self).__name__)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 104])\n",
      "torch.Size([4, 1, 104])\n",
      "torch.Size([2, 1, 104])\n",
      "torch.Size([2, 1, 104])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 69\u001b[0m\n\u001b[1;32m     62\u001b[0m qehvi_sampler \u001b[38;5;241m=\u001b[39m SobolQMCNormalSampler(sample_shape\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mSize([MC_SAMPLES]))\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# qnehvi_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# optimize acquisition functions and get new observations\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# new_x_qparego, new_obj_true_qparego = optimize_qnparego_and_get_observation(\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#     model_qparego, train_x_qparego, train_obj_true_qparego, qparego_sampler\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m new_x_qehvi, new_obj_true_qehvi \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_qehvi_and_get_observation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_qehvi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_x_qehvi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_obj_true_qehvi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqehvi_sampler\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# new_x_qnehvi, new_obj_true_qnehvi = optimize_qnehvi_and_get_observation(\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m#     model_qnehvi, train_x_qnehvi, train_obj_true_qnehvi, qnehvi_sampler\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# train_x_qparego = torch.cat([train_x_qparego, new_x_qparego])\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# train_obj_true_qparego = torch.cat([train_obj_true_qparego, new_obj_true_qparego])\u001b[39;00m\n\u001b[1;32m     83\u001b[0m train_x_qehvi \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([train_x_qehvi, new_x_qehvi])\n",
      "Cell \u001b[0;32mIn[34], line 44\u001b[0m, in \u001b[0;36moptimize_qehvi_and_get_observation\u001b[0;34m(model, train_x, train_obj, sampler)\u001b[0m\n\u001b[1;32m     37\u001b[0m acq_func \u001b[38;5;241m=\u001b[39m qExpectedHypervolumeImprovement(\n\u001b[1;32m     38\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     39\u001b[0m     ref_point\u001b[38;5;241m=\u001b[39mref_point,\n\u001b[1;32m     40\u001b[0m     partitioning\u001b[38;5;241m=\u001b[39mpartitioning,\n\u001b[1;32m     41\u001b[0m     sampler\u001b[38;5;241m=\u001b[39msampler,\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# optimize\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m candidates, _ \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_acqf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_restarts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_RESTARTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRAW_SAMPLES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# used for intialization heuristic\u001b[39;49;00m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequential\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# observe new values\u001b[39;00m\n\u001b[1;32m     55\u001b[0m new_x \u001b[38;5;241m=\u001b[39m unnormalize(candidates\u001b[38;5;241m.\u001b[39mdetach(), bounds\u001b[38;5;241m=\u001b[39mbounds)\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/botorch/optim/optimize.py:543\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, gen_candidates, sequential, ic_generator, timeout_sec, return_full_tree, retry_on_optimization_warning, **ic_gen_kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     gen_candidates \u001b[38;5;241m=\u001b[39m gen_candidates_scipy\n\u001b[1;32m    521\u001b[0m opt_acqf_inputs \u001b[38;5;241m=\u001b[39m OptimizeAcqfInputs(\n\u001b[1;32m    522\u001b[0m     acq_function\u001b[38;5;241m=\u001b[39macq_function,\n\u001b[1;32m    523\u001b[0m     bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     ic_gen_kwargs\u001b[38;5;241m=\u001b[39mic_gen_kwargs,\n\u001b[1;32m    542\u001b[0m )\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_acqf_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/botorch/optim/optimize.py:564\u001b[0m, in \u001b[0;36m_optimize_acqf\u001b[0;34m(opt_inputs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf_sequential_q(opt_inputs\u001b[38;5;241m=\u001b[39mopt_inputs)\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# Batch optimization (including the case q=1)\u001b[39;00m\n\u001b[0;32m--> 564\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/botorch/optim/optimize.py:328\u001b[0m, in \u001b[0;36m_optimize_acqf_batch\u001b[0;34m(opt_inputs)\u001b[0m\n\u001b[1;32m    325\u001b[0m         batch_acq_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(batch_acq_values_list)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch_candidates, batch_acq_values, opt_warnings\n\u001b[0;32m--> 328\u001b[0m batch_candidates, batch_acq_values, ws \u001b[38;5;241m=\u001b[39m \u001b[43m_optimize_batch_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m optimization_warning_raised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    331\u001b[0m     (\u001b[38;5;28missubclass\u001b[39m(w\u001b[38;5;241m.\u001b[39mcategory, OptimizationWarning) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m ws)\n\u001b[1;32m    332\u001b[0m )\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimization_warning_raised \u001b[38;5;129;01mand\u001b[39;00m opt_inputs\u001b[38;5;241m.\u001b[39mretry_on_optimization_warning:\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/botorch/optim/optimize.py:312\u001b[0m, in \u001b[0;36m_optimize_acqf_batch.<locals>._optimize_batch_candidates\u001b[0;34m()\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m ws:\n\u001b[1;32m    308\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39mOptimizationWarning)\n\u001b[1;32m    309\u001b[0m     (\n\u001b[1;32m    310\u001b[0m         batch_candidates_curr,\n\u001b[1;32m    311\u001b[0m         batch_acq_values_curr,\n\u001b[0;32m--> 312\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched_ics_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macq_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m opt_warnings \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ws\n\u001b[1;32m    316\u001b[0m batch_candidates_list\u001b[38;5;241m.\u001b[39mappend(batch_candidates_curr)\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/botorch/generation/gen.py:252\u001b[0m, in \u001b[0;36mgen_candidates_scipy\u001b[0;34m(initial_conditions, acquisition_function, lower_bounds, upper_bounds, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, options, fixed_features, timeout_sec)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(x):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39macquisition_function(x)\n\u001b[0;32m--> 252\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mminimize_with_timeout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_np_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmethod\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSLSQP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallback\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmethod\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallback\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwith_grad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m _process_scipy_result(res\u001b[38;5;241m=\u001b[39mres, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m    270\u001b[0m candidates \u001b[38;5;241m=\u001b[39m fix_features(\n\u001b[1;32m    271\u001b[0m     X\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(res\u001b[38;5;241m.\u001b[39mx)\u001b[38;5;241m.\u001b[39mto(initial_conditions)\u001b[38;5;241m.\u001b[39mreshape(shapeX),\n\u001b[1;32m    272\u001b[0m     fixed_features\u001b[38;5;241m=\u001b[39mfixed_features,\n\u001b[1;32m    273\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/botorch/optim/utils/timeout.py:82\u001b[0m, in \u001b[0;36mminimize_with_timeout\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod .* cannot handle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhessp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapped_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OptimizationTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     97\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization timed out after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mruntime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/scipy/optimize/_minimize.py:731\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    728\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    729\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 731\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    734\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    735\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:347\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    344\u001b[0m         iprint \u001b[38;5;241m=\u001b[39m disp\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# _prepare_scalar_function can use bounds=None to represent no bounds\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m func_and_grad \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun_and_grad\n\u001b[1;32m    353\u001b[0m fortran_int \u001b[38;5;241m=\u001b[39m _lbfgsb\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mintvar\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/scipy/optimize/_optimize.py:288\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    284\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:222\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    219\u001b[0m     finite_diff_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_linear_operator\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# Initial function evaluation\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# Initial gradient evaluation\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped_grad, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ngev \u001b[38;5;241m=\u001b[39m _wrapper_grad(\n\u001b[1;32m    226\u001b[0m     grad,\n\u001b[1;32m    227\u001b[0m     fun\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped_fun,\n\u001b[1;32m    228\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    229\u001b[0m     finite_diff_options\u001b[38;5;241m=\u001b[39mfinite_diff_options\n\u001b[1;32m    230\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:294\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 294\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[1;32m    296\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:20\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     16\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/scipy/optimize/_optimize.py:79\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/scipy/optimize/_optimize.py:73\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 73\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/botorch/generation/gen.py:211\u001b[0m, in \u001b[0;36mgen_candidates_scipy.<locals>.f_np_wrapper\u001b[0;34m(x, f)\u001b[0m\n\u001b[1;32m    209\u001b[0m loss \u001b[38;5;241m=\u001b[39m f(X_fix)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# compute gradient w.r.t. the inputs (does not accumulate in leaves)\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m gradf \u001b[38;5;241m=\u001b[39m _arrayify(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(gradf)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    213\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39misnan(gradf)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m element \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradient array `gradf` are NaN. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis often indicates numerical issues.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/torch/autograd/__init__.py:412\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    408\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    409\u001b[0m         grad_outputs_\n\u001b[1;32m    410\u001b[0m     )\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    423\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    425\u001b[0m     ):\n",
      "File \u001b[0;32m~/miniconda3/envs/matminer-phaseshift/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.utils.multi_objective.box_decompositions.dominated import (\n",
    "    DominatedPartitioning,\n",
    ")\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "N_BATCH = 20 if not SMOKE_TEST else 5\n",
    "MC_SAMPLES = 128 if not SMOKE_TEST else 16\n",
    "\n",
    "verbose = True\n",
    "\n",
    "hvs_qparego, hvs_qehvi, hvs_qnehvi, hvs_random = [], [], [], []\n",
    "\n",
    "# call helper functions to generate initial training data and initialize model\n",
    "# train_x_qparego, train_obj_true_qparego, total_df = generate_initial_data(surrogates)\n",
    "# mll_qparego, model_qparego = initialize_model(train_x_qparego, train_obj_true_qparego)\n",
    "\n",
    "train_x_qehvi, train_obj_true_qehvi, total_df = generate_initial_data(surrogates)\n",
    "# train_x_qnehvi, train_obj_true_qnehvi = (\n",
    "#     train_x_qparego,\n",
    "#     train_obj_true_qparego,\n",
    "# )\n",
    "# train_x_random, train_obj_true_random = (\n",
    "#     train_x_qparego,\n",
    "#     train_obj_true_qparego,\n",
    "# )\n",
    "mll_qehvi, model_qehvi = initialize_model(train_x_qehvi, train_obj_true_qehvi)\n",
    "#mll_qnehvi, model_qnehvi = initialize_model(train_x_qnehvi, train_obj_true_qnehvi)\n",
    "\n",
    "# compute hypervolume\n",
    "bd = DominatedPartitioning(ref_point=ref_point, Y=train_obj_true_qehvi.detach().clone().squeeze(dim=1))\n",
    "volume = bd.compute_hypervolume().item()\n",
    "\n",
    "hvs_qparego.append(volume)\n",
    "hvs_qehvi.append(volume)\n",
    "hvs_qnehvi.append(volume)\n",
    "#hvs_random.append(volume)\n",
    "\n",
    "# run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "for iteration in range(1, N_BATCH + 1):\n",
    "\n",
    "    t0 = time.monotonic()\n",
    "\n",
    "    # fit the models\n",
    "    # train_model(model_qparego, mll_qparego)\n",
    "    model_qehvi.train()\n",
    "    train_model(model_qehvi, mll_qehvi)\n",
    "    model_qehvi.eval\n",
    "    # train_model(model_qnehvi, mll_qnehvi)\n",
    "\n",
    "    # define the qEI and qNEI acquisition modules using a QMC sampler\n",
    "    # qparego_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n",
    "    qehvi_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n",
    "    # qnehvi_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n",
    "\n",
    "    # optimize acquisition functions and get new observations\n",
    "    # new_x_qparego, new_obj_true_qparego = optimize_qnparego_and_get_observation(\n",
    "    #     model_qparego, train_x_qparego, train_obj_true_qparego, qparego_sampler\n",
    "    # )\n",
    "    new_x_qehvi, new_obj_true_qehvi = optimize_qehvi_and_get_observation(\n",
    "        model_qehvi, train_x_qehvi, train_obj_true_qehvi, qehvi_sampler\n",
    "    )\n",
    "    # new_x_qnehvi, new_obj_true_qnehvi = optimize_qnehvi_and_get_observation(\n",
    "    #     model_qnehvi, train_x_qnehvi, train_obj_true_qnehvi, qnehvi_sampler\n",
    "    # )\n",
    "    # new_x_random, new_obj_random, new_obj_true_random = generate_initial_data(\n",
    "    #     n=BATCH_SIZE\n",
    "    # )\n",
    "\n",
    "    # update training points\n",
    "    # train_x_qparego = torch.cat([train_x_qparego, new_x_qparego])\n",
    "    # train_obj_true_qparego = torch.cat([train_obj_true_qparego, new_obj_true_qparego])\n",
    "\n",
    "    train_x_qehvi = torch.cat([train_x_qehvi, new_x_qehvi])\n",
    "    train_obj_true_qehvi = torch.cat([train_obj_true_qehvi, new_obj_true_qehvi], dim=0)\n",
    "\n",
    "    # train_x_qnehvi = torch.cat([train_x_qnehvi, new_x_qnehvi])\n",
    "    # train_obj_true_qnehvi = torch.cat([train_obj_true_qnehvi, new_obj_true_qnehvi])\n",
    "\n",
    "    # train_x_random = torch.cat([train_x_random, new_x_random])\n",
    "    # train_obj_true_random = torch.cat([train_obj_true_random, new_obj_true_random])\n",
    "\n",
    "    # update progress\n",
    "    for hvs_list, train_obj in zip(\n",
    "        (hvs_random, hvs_qparego, hvs_qehvi, hvs_qnehvi),\n",
    "        (\n",
    "            #train_obj_true_random,\n",
    "            # train_obj_true_qparego,\n",
    "            train_obj_true_qehvi,\n",
    "            # train_obj_true_qnehvi,\n",
    "        ),\n",
    "    ):\n",
    "        # compute hypervolume\n",
    "        bd = DominatedPartitioning(ref_point=ref_point, Y=train_obj.detach().clone().squeeze(dim=1))\n",
    "        volume = bd.compute_hypervolume().item()\n",
    "        hvs_list.append(volume)\n",
    "\n",
    "    # reinitialize the models so they are ready for fitting on next iteration\n",
    "    # Note: we find improved performance from not warm starting the model hyperparameters\n",
    "    # using the hyperparameters from the previous iteration\n",
    "    # mll_qparego, model_qparego = initialize_model(train_x_qparego, train_obj_qparego)\n",
    "    mll_qehvi, model_qehvi = initialize_model(train_x_qehvi, train_obj_true_qehvi)\n",
    "    # mll_qnehvi, model_qnehvi = initialize_model(train_x_qnehvi, train_obj_qnehvi)\n",
    "\n",
    "    t1 = time.monotonic()\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"\\nBatch {iteration:>2}: Hypervolume (random, qNParEGO, qEHVI, qNEHVI) = \"\n",
    "            f\"({hvs_random[-1]:>4.2f}, {hvs_qparego[-1]:>4.2f}, {hvs_qehvi[-1]:>4.2f}, {hvs_qnehvi[-1]:>4.2f}), \"\n",
    "            f\"time = {t1-t0:>4.2f}.\",\n",
    "            end=\"\",\n",
    "        )\n",
    "    else:\n",
    "        print(\".\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67998db2-ec0b-481c-b4d8-c05eff6f71d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_x, train_obj, sampler = model_qehvi, train_x_qehvi, train_obj_true_qehvi, qparego_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e2b77-6723-4571-8857-ff41f0ba90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obj_true_qehvi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4927cbd-3e18-4f86-afba-22369af30fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_X, init_y, _ = generate_initial_data(surrogates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b25395f-ef60-4235-800c-ba3c66af672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc79b75-2e6b-41bc-ac96-4ad6d106fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obj_true_qehvi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f169c9f6-f5d6-4cd3-b1ac-0d62ac130e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c105edf6-039d-444d-a7c0-ee767aabb4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc433e9-e448-4e52-955e-374be24bfa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = DominatedPartitioning(ref_point=ref_point, Y=init_y[:10,:,:].squeeze(dim=1))\n",
    "volume = bd.compute_hypervolume().item(); volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e445744-016f-445b-9283-ca74aeefe443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3b4981-e75e-44a9-94fd-1e03fe4309f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = DominatedPartitioning(ref_point=ref_point, Y=train_obj_true_qehvi.squeeze(dim=1))\n",
    "volume = bd.compute_hypervolume().item(); volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b683941c-5036-4fc4-8232-4a8b5afb55ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_obj_true_qehvi.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39d1181-ae75-405f-9a95-11da89e95fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_x, train_obj, sampler = model_qparego, train_x_qparego, train_obj_true_qparego, qparego_sampler\n",
    "\"\"\"Samples a set of random weights for each candidate in the batch, performs sequential greedy optimization\n",
    "of the qNParEGO acquisition function, and returns a new candidate and observation.\"\"\"\n",
    "#train_x = normalize(train_x, bounds)\n",
    "train_x = normalize(train_x, bounds)\n",
    "with torch.no_grad():\n",
    "    pred = model.posterior(train_x).mean\n",
    "acq_func_list = []\n",
    "for _ in range(BATCH_SIZE):\n",
    "    weights = sample_simplex(2, **tkwargs).squeeze()\n",
    "    objective = GenericMCObjective(\n",
    "        get_chebyshev_scalarization(weights=weights, Y=pred)\n",
    "    )\n",
    "    acq_func = qNoisyExpectedImprovement(  # pyre-ignore: [28]\n",
    "        model=model,\n",
    "        objective=objective,\n",
    "        X_baseline=train_x,\n",
    "        sampler=sampler,\n",
    "        prune_baseline=False,\n",
    "    )\n",
    "    acq_func_list.append(acq_func)\n",
    "# optimize\n",
    "candidates, _ = optimize_acqf_list(\n",
    "    acq_function_list=acq_func_list,\n",
    "    bounds=bounds,\n",
    "    num_restarts=1,\n",
    "    raw_samples=512,  # used for intialization heuristic\n",
    "    options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    ")\n",
    "# observe new values\n",
    "new_x = unnormalize(candidates.detach(), bounds=bounds)\n",
    "#new_obj_true = problem(new_x)\n",
    "#new_obj = new_obj_true + torch.randn_like(new_obj_true) * NOISE_SE\n",
    "#return new_x, new_obj_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcd0952-b210-4ccb-a240-3d84a975ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(train_x, bounds).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fae810-fc76-470d-aa3e-fc016bef3b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f030dc-1c3b-4445-97e5-33ad1157ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ed98a-8879-4059-84d1-dcd2e365f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qehvi_sampler(model.posterior(normalize(train_x, bounds))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be981272-b9d2-45de-bd8b-cfd2eb5be49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ad581-aea6-429a-855a-712a178d1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_x, train_obj, sampler = model_qehvi, train_x_qehvi, train_obj_true_qehvi, qehvi_sampler\n",
    "with torch.no_grad():\n",
    "    pred = model.posterior(normalize(train_x, bounds)).mean\n",
    "    #pred = torch.concatenate([model.posterior(train_x[:,:,i]).mean for i, model in enumerate(model_qparego.models)],dim=-1)\n",
    "partitioning = FastNondominatedPartitioning(\n",
    "    ref_point=ref_point,\n",
    "    Y=pred,\n",
    ")\n",
    "acq_func = qExpectedHypervolumeImprovement(\n",
    "    model=model,\n",
    "    ref_point=ref_point,\n",
    "    partitioning=partitioning,\n",
    "    sampler=sampler,\n",
    ")\n",
    "# optimize\n",
    "candidates, _ = optimize_acqf(\n",
    "    acq_function=acq_func,\n",
    "    bounds=bounds,\n",
    "    q=BATCH_SIZE,\n",
    "    num_restarts=NUM_RESTARTS,\n",
    "    raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
    "    options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "    sequential=True,\n",
    ")\n",
    "# observe new values\n",
    "new_x = unnormalize(candidates.detach(), bounds=bounds)\n",
    "print(new_x.shape)\n",
    "new_obj_true = torch.stack([model.models[0](new_x).mean, model.models[1](new_x).mean], dim=-1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa8ac2-dfe8-4ef6-8f80-34b604b2c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa9d80-21c4-4431-b250-5b5710d7b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_acqf(\n",
    "    acq_function=acq_func,\n",
    "    bounds=bounds,\n",
    "    q=BATCH_SIZE,\n",
    "    num_restarts=NUM_RESTARTS,\n",
    "    raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n",
    "    options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "    sequential=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206a1a5d-c2c3-4e6d-a95d-f6f9e666d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.models[0].to_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0129104-27b1-439e-afcb-90e5076d3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd8934-7240-4e5e-85d9-9f3c5ab96bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.posterior(train_x[:,:,0]).mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd28b03d-29c0-4c43-8674-a304e0575b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.posterior(torch.concatenate([train_x[:,:,0],train_x[:,:,1]],dim=0)).mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee571371-4a54-4d76-bf77-d6b65eb63697",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_qparego.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb517368-3dbf-4c3b-a98f-3e47e4b19048",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qparego.posterior(train_x_qparego[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae77b7-7b3c-4b04-8682-e9746f78ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qparego.models[0].posterior(train_x_qparego[:,:,0]).mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f143ef-76b7-494b-8775-8f6040f20705",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.concatenate([model.posterior(train_x_qparego[:,:,i]).mean for i, model in enumerate(model_qparego.models)],dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5bd13f-98df-40af-b32b-1a04cc07a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203006d-2b71-4c41-99a5-7c9f0e8d65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qparego.models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7788d1-bae8-49bd-8a75-0267ffa1ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_qparego.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d71705-4258-44f6-be0f-5bbf22be894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obj_true_qparego.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35adc355-e5ab-4581-bf9d-4b4299f08763",
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = DominatedPartitioning(ref_point=ref_point, Y=train_obj_true_qehvi.squeeze(dim=1))\n",
    "volume = bd.compute_hypervolume().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6661547-1154-46be-913c-1fdf7b2637f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_qehvi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7319d8f-c108-4627-8ddc-4eab767779c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obj_true_qehvi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e4eab1-2db6-49df-b244-c6cdabea15be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qehvi.train_inputs[0][0].shape\n",
    "\n",
    "training_set = [torch.tensor(X[0], **tkwargs) for X in model_qehvi.train_inputs]\n",
    "torch.stack(training_set, dim=-1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07577f0-5ccc-460b-982e-3a91ab49250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qehvi.eval()\n",
    "model_qehvi(train_x_qehvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf846a0-988e-4607-8fd6-9f58e16aabca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_data(surrogates):\n",
    "    from utils.model import evaluateGP\n",
    "    X = np.concatenate([surrogate.X for surrogate in surrogates],axis=0)\n",
    "    y = [evaluateGP(surrogate.model, X) for surrogate in surrogates][0]\n",
    "    X = torch.tensor(X, **tkwargs)\n",
    "    y = [torch.tensor(array, **tkwargs) for array in y]\n",
    "    X = torch.stack((X, X),dim=-1)\n",
    "    y = torch.stack(y,dim=-1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c792629-dd88-4dda-9de0-1cf8f0601639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model import evaluateGP\n",
    "X = []\n",
    "X = np.concatenate([surrogate.X for surrogate in surrogates],axis=0)\n",
    "y = [evaluateGP(surrogate.model, X) for surrogate in surrogates][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94036f16-f17d-4964-a2c6-ea794bfeb101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc9dacf-5fe8-4b18-83e9-38fa605579f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ded72-8f07-472a-b628-8f8a0ca33922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f2c646-8c65-4e22-ab4b-97a5078d20e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = generate_initial_data(surrogates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5dc0a1-73cc-4292-aa75-8ff0bc045d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310196cd-b5e4-4aee-b66e-c8bedd6bdc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d16d025-284b-4e1b-a80c-0dcfe5450ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da9e0ca-5f79-4477-b790-1d7cabe9de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7704f20-fe88-415d-9ec5-cd6f2220e0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
